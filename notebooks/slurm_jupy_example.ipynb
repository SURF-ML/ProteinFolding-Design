{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad6bcc73-bead-4740-bb4d-854acf571c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/home4/bryanc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get current working directory\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# Print the path\n",
    "print(current_path)\n",
    "\n",
    "def submit_slurm_job(slurm_script_content, script_filename=\"submit_job.sh\"):\n",
    "    \"\"\"\n",
    "    Writes a Slurm script to a file and submits it using sbatch.\n",
    "\n",
    "    Args:\n",
    "        slurm_script_content (str): A string containing the entire Slurm script.\n",
    "        script_filename (str, optional): The name of the file to write the script to. \n",
    "                                         Defaults to \"submit_job.sh\".\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the job was submitted successfully, False otherwise.\n",
    "    \"\"\"\n",
    "    # Write the string content to the specified .sh file\n",
    "    try:\n",
    "        with open(script_filename, \"w\") as f:\n",
    "            f.write(slurm_script_content)\n",
    "    except IOError as e:\n",
    "        print(f\"❌ Error writing script file: {e}\")\n",
    "        return False\n",
    "\n",
    "    # Use subprocess to run the sbatch command\n",
    "    try:\n",
    "        # The 'check=True' argument will raise an error if sbatch fails\n",
    "        result = subprocess.run(\n",
    "            [\"sbatch\", script_filename],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        print(\"✅ Job submitted successfully!\")\n",
    "        print(result.stdout)  # This usually contains the job ID\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ Error: 'sbatch' command not found.\")\n",
    "        print(\"Please ensure you are on a system with Slurm installed.\")\n",
    "        return False\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"❌ Error submitting job via sbatch:\")\n",
    "        print(e.stderr)  # Print the error message from Slurm\n",
    "        return False\n",
    "    finally:\n",
    "        # The script file is kept for inspection but you could remove it.\n",
    "        # To clean up, uncomment the following line:\n",
    "        #os.remove(script_filename)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7338d17a-7beb-4ded-a71c-f2af1ca3b985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Job submitted successfully!\n",
      "Submitted batch job 14062594\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Define the Slurm script as a multi-line string\n",
    "slurm_script_content = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name=rfdiffusion_scaffold    # Name of the job\n",
    "#SBATCH --nodes=1                          # Request a single node\n",
    "#SBATCH --time=00:10:00                    # Maximum execution time: 20 minutes\n",
    "#SBATCH --partition=gpu_a100               # Request the A100 GPU partition\n",
    "#SBATCH --gpus=1                           # Request one GPU\n",
    "#SBATCH --ntasks=1                         # Run a single task\n",
    "#SBATCH --cpus-per-task=8                  # Allocate 8 CPUs for the task\n",
    "#SBATCH --output=rfdiffusion_%j.out        # Standard output log\n",
    "#SBATCH --error=rfdiffusion_%j.err         # Standard error log\n",
    "\n",
    "# Define the base project directory\n",
    "PROJECT_SPACE=\"/projects/0/prjs0823/apptainers\"\n",
    "\n",
    "echo \"$PROJECT_SPACE\"\n",
    "\n",
    "# Paths for the RFdiffusion container and input files\n",
    "RFD_CONTAINER_PATH=\"$PROJECT_SPACE/rfdiffusion/containers/rfdiffusion-cuda11.8.sif\"\n",
    "INPUT_PDB_PATH=\"$PROJECT_SPACE/rfdiffusion/examples/5TPN.pdb\"\n",
    "OUTPUT_PATH=\"$PROJECT_SPACE/out/\"\n",
    "OVERLAY_FILE=\"$PROJECT_SPACE/rfdiffusion_overlay.img\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "mkdir -p \"$OUTPUT_PATH\"\n",
    "\n",
    "# Create an overlay file for writable storage inside the container\n",
    "# We add --force to overwrite an existing overlay file from a previous run\n",
    "apptainer overlay create --size 128 \"$OVERLAY_FILE\"\n",
    "\n",
    "# Run RFdiffusion using an Apptainer container\n",
    "apptainer run --nv \\\\\n",
    "    --overlay \"$OVERLAY_FILE\" \\\\\n",
    "    -B \"$PWD:/workspace\" \\\\\n",
    "    --pwd /workspace \\\\\n",
    "    \"$RFD_CONTAINER_PATH\" \\\\\n",
    "    inference.output_prefix=\"$OUTPUT_PATH/design\" \\\\\n",
    "    inference.input_pdb=\"$INPUT_PDB_PATH\" \\\\\n",
    "    inference.num_designs=1 \\\\\n",
    "    'contigmap.contigs=[10-40/A163-181/10-40]' \\\\\n",
    "    inference.model_directory_path=/app/RFdiffusion/models\n",
    "\"\"\"\n",
    "\n",
    "# Define the name for the temporary script file\n",
    "submit_slurm_job(slurm_script_content, script_filename=\"submit_job_rfd.job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8bae64-1426-4de9-b955-e788e1e283a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
